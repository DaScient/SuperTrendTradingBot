{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dascient/cryptoforecast-univariate-lstm-rnn-approach?scriptVersionId=216315614\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Authors: dtad & jcre\n## Inspiration: https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n\n# Welcome to our Universe\n## [@donutz.ai](www.donutz,ai/#)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:17:42.855871Z","iopub.execute_input":"2021-11-18T09:17:42.856479Z","iopub.status.idle":"2021-11-18T09:17:42.860086Z","shell.execute_reply.started":"2021-11-18T09:17:42.856443Z","shell.execute_reply":"2021-11-18T09:17:42.859293Z"}}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nfrom IPython.display import clear_output\nclear_output()\nimport time,csv\nimport matplotlib.pyplot as plt\nfrom dateutil.tz import tzlocal\nfrom datetime import datetime\nimport seaborn as sns\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:25:53.222332Z","iopub.execute_input":"2021-11-21T21:25:53.223138Z","iopub.status.idle":"2021-11-21T21:25:54.021934Z","shell.execute_reply.started":"2021-11-21T21:25:53.223097Z","shell.execute_reply":"2021-11-21T21:25:54.021067Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# load kaggle data","metadata":{}},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        clear_output()\n\n# could've done this better, but hey...\n# for kaggle\n# rootdir = '/kaggle/input/g-research-crypto-forecasting/'\n\n# for home\nrootdir = '/kaggle/input/g-research-crypto-forecasting/'\n\n# data pull\nexample_sample_submission = pd.read_csv(rootdir+'example_sample_submission.csv')\nasset_details = pd.read_csv(rootdir+'asset_details.csv')\nexample_test = pd.read_csv(rootdir+'example_test.csv')\ntrain = pd.read_csv(rootdir+'train.csv')\nsupplemental_train = pd.read_csv(rootdir+'supplemental_train.csv')\n\nprint('csv/files loaded')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:25:57.162805Z","iopub.execute_input":"2021-11-21T21:25:57.163113Z","iopub.status.idle":"2021-11-21T21:26:51.012304Z","shell.execute_reply.started":"2021-11-21T21:25:57.163082Z","shell.execute_reply":"2021-11-21T21:26:51.011438Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# timestamping \nsupplemental_train['timestamp'] = supplemental_train.timestamp.astype('datetime64[s]')\nexample_test['timestamp'] = example_test.timestamp.astype('datetime64[s]')\ntrain['timestamp'] = train.timestamp.astype('datetime64[s]')\nprint('timestamping complete')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:26:51.014187Z","iopub.execute_input":"2021-11-21T21:26:51.014485Z","iopub.status.idle":"2021-11-21T21:26:53.298888Z","shell.execute_reply.started":"2021-11-21T21:26:51.014446Z","shell.execute_reply":"2021-11-21T21:26:53.298037Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# begin tensorflow application","metadata":{}},{"cell_type":"markdown","source":"[](http://)","metadata":{}},{"cell_type":"code","source":"import numpy\nimport matplotlib.pyplot as plt\nimport math\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:26:53.300273Z","iopub.execute_input":"2021-11-21T21:26:53.300937Z","iopub.status.idle":"2021-11-21T21:26:58.619385Z","shell.execute_reply.started":"2021-11-21T21:26:53.300904Z","shell.execute_reply":"2021-11-21T21:26:58.618542Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return numpy.array(dataX), numpy.array(dataY)\n\n# fix random seed for reproducibility\nnumpy.random.seed(7)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:26:58.620986Z","iopub.execute_input":"2021-11-21T21:26:58.621216Z","iopub.status.idle":"2021-11-21T21:26:58.62713Z","shell.execute_reply.started":"2021-11-21T21:26:58.62119Z","shell.execute_reply":"2021-11-21T21:26:58.626557Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load the dataset\n# isolate to only one asset, for now...\n# this also assumes only one variable - & we do not expect to output a complete \"submission.csv\"\ndataframe = supplemental_train[supplemental_train.Asset_ID == 8][['Close']].reset_index(drop=True).head(100)\n\ndataset = dataframe.values\ndataset = dataset.astype('float32')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:26:58.628054Z","iopub.execute_input":"2021-11-21T21:26:58.628706Z","iopub.status.idle":"2021-11-21T21:26:58.68019Z","shell.execute_reply.started":"2021-11-21T21:26:58.628647Z","shell.execute_reply":"2021-11-21T21:26:58.679575Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:26:58.681301Z","iopub.execute_input":"2021-11-21T21:26:58.681919Z","iopub.status.idle":"2021-11-21T21:26:58.686007Z","shell.execute_reply.started":"2021-11-21T21:26:58.681888Z","shell.execute_reply":"2021-11-21T21:26:58.685269Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# split into train and test sets\ntrain_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n\n# reshape into X=t and Y=t+1\nlook_back = 3\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n\n# reshape input to be [samples, time steps, features]\ntrainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\ntestX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:26:58.687091Z","iopub.execute_input":"2021-11-21T21:26:58.687445Z","iopub.status.idle":"2021-11-21T21:26:58.703652Z","shell.execute_reply.started":"2021-11-21T21:26:58.687419Z","shell.execute_reply":"2021-11-21T21:26:58.70294Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create and fit the LSTM network\n# could change batch_size\nbatch_size = 1\n\nmodel = Sequential()\nmodel.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\nmodel.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:26:58.705083Z","iopub.execute_input":"2021-11-21T21:26:58.705723Z","iopub.status.idle":"2021-11-21T21:26:59.271954Z","shell.execute_reply.started":"2021-11-21T21:26:58.705694Z","shell.execute_reply":"2021-11-21T21:26:59.270983Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# trains _ samples 10x \nfor i in range(10):\n    model.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n    model.reset_states()\n\nclear_output()\n\n# make predictions\ntrainPredict = model.predict(trainX, batch_size=batch_size)\nmodel.reset_states()\ntestPredict = model.predict(testX, batch_size=batch_size)\n\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:26:59.273018Z","iopub.execute_input":"2021-11-21T21:26:59.27322Z","iopub.status.idle":"2021-11-21T21:27:05.346958Z","shell.execute_reply.started":"2021-11-21T21:26:59.273197Z","shell.execute_reply":"2021-11-21T21:27:05.346262Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.6f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.6f RMSE' % (testScore))\n# shift train predictions for plotting\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n# shift test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.figure(figsize=(18,7))\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:27:05.349769Z","iopub.execute_input":"2021-11-21T21:27:05.350552Z","iopub.status.idle":"2021-11-21T21:27:05.594219Z","shell.execute_reply.started":"2021-11-21T21:27:05.350516Z","shell.execute_reply":"2021-11-21T21:27:05.591691Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"#import gresearch_crypto\n#env = gresearch_crypto.make_env()\n\n# Training data is in the competition dataset as usual\n#train_df = pd.read_csv('/kaggle/input/g-research-crypto-forecasting/train.csv', low_memory=False)\n\n# load model\n#model.fit(train_df)\n#model.fit(train_df)\n\n#iter_test = env.iter_test()\n\n#for (test_df, sample_prediction_df) in iter_test:\n#    sample_prediction_df['Target'] = model.predict(test_df)\n#    env.predict(sample_prediction_df)\n\n\n# submission\n#sample_prediction_df['Target'].to_csv('submission.csv', index=False)\nprint(\"project complete, for now.\")","metadata":{"execution":{"iopub.status.busy":"2021-11-21T21:40:48.111248Z","iopub.status.idle":"2021-11-21T21:40:48.111794Z","shell.execute_reply.started":"2021-11-21T21:40:48.111584Z","shell.execute_reply":"2021-11-21T21:40:48.111604Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# still need output: submission.csv\n\n# to be continued...","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:45:21.38512Z","iopub.execute_input":"2021-11-18T09:45:21.385351Z","iopub.status.idle":"2021-11-18T09:45:21.395983Z","shell.execute_reply.started":"2021-11-18T09:45:21.385324Z","shell.execute_reply":"2021-11-18T09:45:21.395069Z"},"trusted":true},"outputs":[],"execution_count":null}]}