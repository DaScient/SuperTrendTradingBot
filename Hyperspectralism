{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":""}},"nbformat_minor":5,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dascient/hyperspectralism?scriptVersionId=217866694\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"id":"19b7abaa","cell_type":"markdown","source":"# Hyperspectral Imagery Analysis with Python\nIn this notebook, we will explore hyperspectral imagery processing using modern edge-AI techniques. We will generate synthetic data, reduce dimensions using PCA, perform segmentation using clustering, and train an autoencoder for feature extraction. Enjoy learning! ğŸ˜„","metadata":{}},{"id":"73886070","cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.transforms import functional as F","metadata":{},"outputs":[],"execution_count":null},{"id":"22c69882","cell_type":"markdown","source":"## Generate Synthetic Hyperspectral Data\nFirst, we'll generate a synthetic hyperspectral data cube to simulate the kind of data used in remote sensing and other applications.","metadata":{}},{"id":"ddf92213","cell_type":"code","source":"# Generate synthetic hyperspectral data (cube)\ndef generate_hyperspectral_cube(ğ›Œ, ğ›¼, ğ›½):\n    np.random.seed(42)\n    spectral_bands = np.linspace(ğ›¼, ğ›½, ğ›Œ)\n    spatial_dim = 128\n    cube = np.zeros((spatial_dim, spatial_dim, ğ›Œ))\n\n    for i, band in enumerate(spectral_bands):\n        cube[:, :, i] = np.sin(2 * np.pi * (np.indices((spatial_dim, spatial_dim))[0] + band)) + np.random.normal(0, 0.1, (spatial_dim, spatial_dim))\n\n    return cube\n\n# Generate the cube\nğ›Œ = 50  # Number of spectral bands\nğ›¼ = 0.4\nğ›½ = 0.8\nğ›· = generate_hyperspectral_cube(ğ›Œ, ğ›¼, ğ›½)","metadata":{},"outputs":[],"execution_count":null},{"id":"4444120e","cell_type":"markdown","source":"## Visualize a Spectral Band\nLet's visualize one of the spectral bands from the hyperspectral cube.","metadata":{}},{"id":"cb8ac0af","cell_type":"code","source":"# Display a single band\ndef display_band(ğ›·, band_index):\n    plt.imshow(ğ›·[:, :, band_index], cmap='viridis')\n    plt.title(f\"Spectral Band {band_index}\")\n    plt.colorbar()\n    plt.show()\n\n# Visualize the 10th band\ndisplay_band(ğ›·, 10)","metadata":{},"outputs":[],"execution_count":null},{"id":"0e71fa33","cell_type":"markdown","source":"## PCA for Dimensionality Reduction\nWe apply Principal Component Analysis (PCA) to reduce the spectral dimensions while retaining most of the information.","metadata":{}},{"id":"30aaa69f","cell_type":"code","source":"# PCA for dimensionality reduction\ndef apply_pca(ğ›·, n_components):\n    reshaped_cube = ğ›·.reshape(-1, ğ›·.shape[2])\n    pca = PCA(n_components=n_components)\n    reduced = pca.fit_transform(reshaped_cube)\n    return reduced.reshape(ğ›·.shape[0], ğ›·.shape[1], n_components), pca\n\n# Apply PCA\nreduced_ğ›·, pca = apply_pca(ğ›·, n_components=3)\nplt.imshow(reduced_ğ›·[:, :, 0], cmap='magma')\nplt.title(\"PCA Reduced Band 0\")\nplt.colorbar()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"175af51c","cell_type":"markdown","source":"## Clustering for Segmentation\nUsing KMeans clustering, we segment the reduced hyperspectral data into meaningful clusters.","metadata":{}},{"id":"eeb99547","cell_type":"code","source":"# Clustering for segmentation\ndef segment_hyperspectral(ğ›·, clusters):\n    reshaped_cube = ğ›·.reshape(-1, ğ›·.shape[2])\n    kmeans = KMeans(n_clusters=clusters, random_state=42)\n    labels = kmeans.fit_predict(reshaped_cube)\n    return labels.reshape(ğ›·.shape[0], ğ›·.shape[1])\n\n# Segment the hyperspectral data\nsegmented = segment_hyperspectral(reduced_ğ›·, clusters=5)\nplt.imshow(segmented, cmap='tab20')\nplt.title(\"Segmented Hyperspectral Image\")\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"36f3c9ba","cell_type":"markdown","source":"## Autoencoder for Feature Extraction\nWe build and train an autoencoder to extract features from the hyperspectral data.","metadata":{}},{"id":"4f3fa420","cell_type":"code","source":"# Simple Autoencoder for feature extraction\nclass HyperspectralAutoencoder(nn.Module):\n    def __init__(self, input_dim, bottleneck_dim):\n        super(HyperspectralAutoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, bottleneck_dim)\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(bottleneck_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, input_dim)\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return encoded, decoded\n\n# Train the Autoencoder\ndef train_autoencoder(ğ›·, epochs=50, bottleneck_dim=16):\n    reshaped_cube = ğ›·.reshape(-1, ğ›·.shape[2])\n    reshaped_cube = MinMaxScaler().fit_transform(reshaped_cube)\n\n    model = HyperspectralAutoencoder(ğ›·.shape[2], bottleneck_dim)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    tensor_cube = torch.FloatTensor(reshaped_cube)\n    for epoch in range(epochs):\n        optimizer.zero_grad()\n        _, decoded = model(tensor_cube)\n        loss = criterion(decoded, tensor_cube)\n        loss.backward()\n        optimizer.step()\n        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.6f}\")\n\n    return model\n\n# Train the autoencoder\nautoencoder = train_autoencoder(ğ›·)\nprint(\"Autoencoder trained successfully!\")","metadata":{},"outputs":[],"execution_count":null}]}